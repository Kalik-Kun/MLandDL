{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## week03: Логистическая регрессия и анализ изображений\n",
    "\n",
    "\n",
    "В этом ноутбуке предлагается построить классификатор изображений на основе логистической регрессии. \n",
    "\n",
    "*Забегая вперед, мы попробуем решить задачу классификации изображений используя лишь простые методы. В третьей части нашего курса мы вернемся к этой задаче.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Постановка задачи ##\n",
    "\n",
    "\n",
    "**Задача**: Есть датасет [прямая ссылка](https://drive.google.com/file/d/15tOimf2QYWsMtPJXTUCwgZaOTF8Nxcsm/view?usp=sharing) (\"catvnoncat.h5\") состоящий из:\n",
    "    - обучающей выборки из m_train изображений, помеченных \"cat\" (y=1) или \"non-cat\" (y=0)\n",
    "    - тестовой выборки m_test изображений, помеченных \"cat\" или \"non-cat\"\n",
    "    - каждое цветное изображение имеет размер (src_size, src_size, 3), где 3 - число каналов (RGB).\n",
    "    Таким образом, каждый слой - квадрат размера src_size x src_size$.\n",
    "\n",
    "Давайте построим простой алгоритм классификации изображений на классы \"cat\"/\"non-cat\".\n",
    "\n",
    "Автоматическая загрузка доступна ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/LogReg_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "\n",
    "**Recap**:\n",
    "\n",
    "Для каждого примера $x^{(i)}$:\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "Функция потерь:\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this cell to download the data\n",
    "\n",
    "# !wget \"https://downloader.disk.yandex.ru/disk/7ef1d1e30e23740a4a30799a825319154815ddc85bf689542add0a3d11ccb91c/5d7fdcb0/3dcxK38Q0fG3ui0g2gMZgKkLls8ULwVpoYNkWpBm9d24EceJ6mIoH5l3_wKkFv3PfZ0WMGYjfJULynuJkuGaug%3D%3D?uid=76549735&filename=data.zip&disposition=attachment&hash=&limit=0&content_type=application%2Fzip&owner_uid=76549735&fsize=2815580&hid=084389255415f71a92d0f1024ab741d4&media_type=compressed&tknv=v2&etag=2b348ac8eca72d223108e36b2a671210\" -O data.zip\n",
    "# !unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Загрузка данных и визуализация ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_data = h5py.File(\"data/train_catvnoncat.h5\", \"r\")\n",
    "    train_set_x_orig = np.array(train_data[\"train_set_x\"][:]) # признаки\n",
    "    train_set_y_orig = np.array(train_data[\"train_set_y\"][:]) # метки классов\n",
    "\n",
    "    test_data = h5py.File(\"data/test_catvnoncat.h5\", \"r\")\n",
    "    test_set_x_orig = np.array(test_data[\"test_set_x\"][:]) # признаки\n",
    "    test_set_y_orig = np.array(test_data[\"test_set_y\"][:]) # метки классов\n",
    "\n",
    "    classes = np.array(test_data[\"list_classes\"][:]) # the list of classes\n",
    "    classes = np.array(list(map(lambda x: x.decode('utf-8'), classes)))\n",
    "    \n",
    "    train_set_y = train_set_y_orig.reshape(train_set_y_orig.shape[0])\n",
    "    test_set_y = test_set_y_orig.reshape(test_set_y_orig.shape[0])\n",
    "    return train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_x_orig[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цветные изображения в формате RGB представлены в виде трёхмерных numpy.array.\n",
    "\n",
    "Порядок измерений $H \\times W \\times C$: $H$ - высота, $W$ - ширина и $C$ - число каналов.\n",
    "\n",
    "Значение каждого пиксела находится в интервале $[0;255]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916a7b94119f4d5c9ea032cca03b4a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=208), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_image_interact(i=0)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def show_image_interact(i=0):\n",
    "    f, ax = plt.subplots(1,4, figsize=(15,20), sharey=True)\n",
    "    \n",
    "    ax[0].imshow(train_set_x_orig[i])\n",
    "    ax[0].set_title('RGB image')\n",
    "    ax[1].imshow(train_set_x_orig[i][:,:,0])\n",
    "    ax[1].set_title('R channel')\n",
    "    ax[2].imshow(train_set_x_orig[i][:,:,1])\n",
    "    ax[2].set_title('G channel')\n",
    "    ax[3].imshow(train_set_x_orig[i][:,:,2])\n",
    "    ax[3].set_title('B channel')\n",
    "    \n",
    "    print(\"y = {} belongs to '{}' class.\".format(str(train_set_y[i]),classes[np.squeeze(train_set_y[i])]))\n",
    "\n",
    "interact(show_image_interact,\n",
    "         i=widgets.IntSlider(min=0, max=len(train_set_y)-1, step=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При работе с данными полезно будет сохранить размерности входных изображений для дальнейшей обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: m_train = 209\n",
      "Размер тестовой выборки: m_test = 50\n",
      "Ширина/Высота каждого изображения: src_size = 64\n",
      "Размерны трёхмерной матрицы для каждого изображения: (64, 64, 3)\n",
      "Размерность train_set_x: (209, 64, 64, 3)\n",
      "Размерность train_set_y: (209,)\n",
      "Размерность test_set_x: (50, 64, 64, 3)\n",
      "Размерность test_set_y: (50,)\n"
     ]
    }
   ],
   "source": [
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "src_size = train_set_x_orig.shape[1]\n",
    "\n",
    "print (\"Размер обучающей выборки: m_train = \" + str(m_train))\n",
    "print (\"Размер тестовой выборки: m_test = \" + str(m_test))\n",
    "print (\"Ширина/Высота каждого изображения: src_size = \" + str(src_size))\n",
    "print (\"Размерны трёхмерной матрицы для каждого изображения: (\" + str(src_size) + \", \" + str(src_size) + \", 3)\")\n",
    "print (\"Размерность train_set_x: \" + str(train_set_x_orig.shape))\n",
    "print (\"Размерность train_set_y: \" + str(train_set_y.shape))\n",
    "print (\"Размерность test_set_x: \" + str(test_set_x_orig.shape))\n",
    "print (\"Размерность test_set_y: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Предварительная обработка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем входные изображения размера (num_px, num_px, 3) в вектор признаков размера (num_px $*$ num_px $*$ 3, 1), чтобы сформировать матрицы объект-признак в виде numpy-array для обучающей и тестовой выборок.\n",
    "\n",
    "Каждой строке матрицы объект-признак соответствует входное развёрнутое в вектор-строку изображение.\n",
    "\n",
    "Помимо этого, для предварительной обработки (препроцессинга) изображений применяют центрирование значений: из значения каждого пиксела вычитается среднее и делят полученное значение на среднеквадратичное отклонение значений пикселей всего изображения.\n",
    "\n",
    "Однако, на практике обычно просто делят значения пикселей на 255 (максимальное значение пикселя).\n",
    "\n",
    "Оформим эти шаги в функцию предварительной обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 68.24666341],\n",
       "       [111.46508789],\n",
       "       [133.14973958],\n",
       "       [ 57.01822917],\n",
       "       [ 64.0086263 ],\n",
       "       [ 57.30900065],\n",
       "       [ 63.30525716],\n",
       "       [ 76.60058594],\n",
       "       [ 95.82682292],\n",
       "       [ 83.15388997],\n",
       "       [131.06477865],\n",
       "       [108.03198242],\n",
       "       [ 82.48990885],\n",
       "       [139.74739583],\n",
       "       [122.53409831],\n",
       "       [148.3980306 ],\n",
       "       [129.62451172],\n",
       "       [157.26171875],\n",
       "       [120.11368815],\n",
       "       [ 56.83455404],\n",
       "       [112.65454102],\n",
       "       [ 68.20402018],\n",
       "       [166.65030924],\n",
       "       [153.19254557],\n",
       "       [127.44783529],\n",
       "       [ 40.5012207 ],\n",
       "       [ 97.6636556 ],\n",
       "       [109.92643229],\n",
       "       [ 75.72241211],\n",
       "       [ 91.47688802],\n",
       "       [ 49.84684245],\n",
       "       [129.70019531],\n",
       "       [106.12052409],\n",
       "       [123.3030599 ],\n",
       "       [ 76.        ],\n",
       "       [ 75.68693034],\n",
       "       [ 93.61376953],\n",
       "       [158.96419271],\n",
       "       [ 21.56803385],\n",
       "       [ 97.09505208],\n",
       "       [ 92.58789062],\n",
       "       [ 40.13785807],\n",
       "       [113.22680664],\n",
       "       [126.15071615],\n",
       "       [101.02124023],\n",
       "       [ 62.99031576],\n",
       "       [109.54907227],\n",
       "       [ 85.11311849],\n",
       "       [ 70.97770182],\n",
       "       [ 94.97566732],\n",
       "       [153.96590169],\n",
       "       [113.93717448],\n",
       "       [115.64640299],\n",
       "       [153.12736003],\n",
       "       [ 78.81225586],\n",
       "       [141.74064128],\n",
       "       [ 93.40055339],\n",
       "       [173.72566732],\n",
       "       [ 45.32552083],\n",
       "       [ 71.87133789],\n",
       "       [ 78.76391602],\n",
       "       [ 97.52921549],\n",
       "       [123.19458008],\n",
       "       [ 85.77115885],\n",
       "       [171.52164714],\n",
       "       [ 70.57910156],\n",
       "       [135.5164388 ],\n",
       "       [ 97.11783854],\n",
       "       [121.59383138],\n",
       "       [129.28613281],\n",
       "       [118.49869792],\n",
       "       [ 84.4761556 ],\n",
       "       [ 50.47957357],\n",
       "       [ 83.73795573],\n",
       "       [109.38061523],\n",
       "       [126.55875651],\n",
       "       [ 81.0949707 ],\n",
       "       [ 82.71321615],\n",
       "       [ 77.75968424],\n",
       "       [ 38.45157878],\n",
       "       [ 93.13354492],\n",
       "       [123.58048503],\n",
       "       [ 56.49365234],\n",
       "       [ 63.85424805],\n",
       "       [114.43465169],\n",
       "       [106.01546224],\n",
       "       [125.92716471],\n",
       "       [ 71.29638672],\n",
       "       [113.03295898],\n",
       "       [ 57.23095703],\n",
       "       [124.2722168 ],\n",
       "       [103.4046224 ],\n",
       "       [ 82.72973633],\n",
       "       [ 95.50032552],\n",
       "       [113.55143229],\n",
       "       [153.89705404],\n",
       "       [139.13566081],\n",
       "       [ 91.38419596],\n",
       "       [147.47184245],\n",
       "       [115.69783529],\n",
       "       [119.89086914],\n",
       "       [ 95.02913411],\n",
       "       [122.40291341],\n",
       "       [ 93.35245768],\n",
       "       [ 81.31266276],\n",
       "       [136.77400716],\n",
       "       [139.47249349],\n",
       "       [ 98.73738607],\n",
       "       [ 95.69669596],\n",
       "       [124.72151693],\n",
       "       [125.28434245],\n",
       "       [102.94059245],\n",
       "       [ 60.67879232],\n",
       "       [123.43229167],\n",
       "       [140.11092122],\n",
       "       [107.52872721],\n",
       "       [112.95833333],\n",
       "       [ 90.27596029],\n",
       "       [ 74.1097819 ],\n",
       "       [116.19897461],\n",
       "       [ 98.43652344],\n",
       "       [148.81958008],\n",
       "       [103.73828125],\n",
       "       [116.19099935],\n",
       "       [108.57625326],\n",
       "       [ 86.56819661],\n",
       "       [101.81445312],\n",
       "       [ 78.27408854],\n",
       "       [136.81355794],\n",
       "       [ 61.06461589],\n",
       "       [ 91.5324707 ],\n",
       "       [117.7327474 ],\n",
       "       [ 89.63826497],\n",
       "       [ 76.96020508],\n",
       "       [ 84.16153971],\n",
       "       [146.54231771],\n",
       "       [142.28857422],\n",
       "       [141.59830729],\n",
       "       [106.94783529],\n",
       "       [ 80.42382812],\n",
       "       [111.41959635],\n",
       "       [118.2639974 ],\n",
       "       [105.93546549],\n",
       "       [ 48.50423177],\n",
       "       [149.22900391],\n",
       "       [ 98.12312826],\n",
       "       [136.15405273],\n",
       "       [122.08992513],\n",
       "       [ 46.60351562],\n",
       "       [119.8589681 ],\n",
       "       [143.9671224 ],\n",
       "       [ 62.3680013 ],\n",
       "       [103.74544271],\n",
       "       [115.65828451],\n",
       "       [ 62.40380859],\n",
       "       [112.27237956],\n",
       "       [108.37027995],\n",
       "       [ 65.78556315],\n",
       "       [133.09138997],\n",
       "       [ 95.2590332 ],\n",
       "       [ 74.63964844],\n",
       "       [115.42871094],\n",
       "       [127.31998698],\n",
       "       [101.1566569 ],\n",
       "       [139.87133789],\n",
       "       [ 68.84350586],\n",
       "       [128.23958333],\n",
       "       [110.86385091],\n",
       "       [ 91.81136068],\n",
       "       [131.34342448],\n",
       "       [119.5386556 ],\n",
       "       [102.95369466],\n",
       "       [138.63907878],\n",
       "       [126.56746419],\n",
       "       [125.62874349],\n",
       "       [ 80.93155924],\n",
       "       [105.75553385],\n",
       "       [ 99.70678711],\n",
       "       [ 87.30875651],\n",
       "       [ 98.10945638],\n",
       "       [ 83.70646159],\n",
       "       [140.55208333],\n",
       "       [105.49145508],\n",
       "       [131.23551432],\n",
       "       [ 91.76106771],\n",
       "       [108.53450521],\n",
       "       [ 77.10677083],\n",
       "       [104.7487793 ],\n",
       "       [120.91870117],\n",
       "       [100.56404622],\n",
       "       [141.68619792],\n",
       "       [142.11612956],\n",
       "       [108.92960612],\n",
       "       [170.64070638],\n",
       "       [ 81.28263346],\n",
       "       [ 13.12345378],\n",
       "       [109.06486003],\n",
       "       [100.99243164],\n",
       "       [ 86.44840495],\n",
       "       [ 82.06917318],\n",
       "       [119.19799805],\n",
       "       [127.75032552],\n",
       "       [111.21500651],\n",
       "       [ 94.17765299],\n",
       "       [165.49064128],\n",
       "       [ 23.50984701],\n",
       "       [115.42561849],\n",
       "       [ 20.99544271],\n",
       "       [ 61.08561198]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(np.mean(np.ravel(train_set_x_orig).reshape((209, 64*64*3)), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12920512, -0.09390777, -0.03087677, ..., -0.1720662 ,\n",
       "        -0.1720662 , -0.1720662 ],\n",
       "       [ 0.18971531,  0.18073842,  0.17624997, ..., -0.06612627,\n",
       "        -0.07061472, -0.06837049],\n",
       "       [-0.22169297, -0.26936911, -0.2823717 , ...,  0.02102198,\n",
       "         0.03402456,  0.03835876],\n",
       "       ...,\n",
       "       [ 0.08250746,  0.1184136 ,  0.14833538, ..., -0.09103887,\n",
       "        -0.02521095,  0.10046053],\n",
       "       [ 0.00416023,  0.01244294,  0.00830159, ..., -0.07038418,\n",
       "        -0.06624283, -0.08694961],\n",
       "       [-0.17582569, -0.10958338, -0.02678048, ..., -0.20232262,\n",
       "        -0.20232262, -0.20232262]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA = np.ravel(train_set_x_orig).reshape((209, 64*64*3))\n",
    "DATA_mean = np.vstack(np.mean(DATA, axis=1))\n",
    "(DATA - DATA_mean)/np.vstack(np.sqrt(np.sum((DATA - DATA_mean)**2, axis=1) / 209))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing_simple(data):\n",
    "    assert type(data) == np.ndarray\n",
    "    assert data.ndim == 4\n",
    "    \n",
    "    n,h,w,c = data.shape\n",
    "    data_vectorized = np.ravel(data).reshape((n, h*w*c))\n",
    "    data_mean = np.vstack(np.mean(data_vectorized, axis=1))\n",
    "    data_normalized = (data_vectorized - data_mean) /np.vstack(np.sqrt(np.sum((data_vectorized - data_mean)**2, axis=1) / n))\n",
    "    \n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "Размеры train_set_x_vectorized:  (209, 12288)\n",
      "Размеры train_set_y:             (209,)\n",
      "Размеры классов 'cat'/'non-cat': 72 / 137\n",
      "Test set:\n",
      "Размеры test_set_x_vectorized:   (50, 12288)\n",
      "Размеры test_set_y:              (50,)\n",
      "Размеры классов 'cat'/'non-cat': 33 / 17\n"
     ]
    }
   ],
   "source": [
    "# Изменить размеры входных данных\n",
    "\n",
    "train_set_x_vectorized = image_preprocessing_simple(train_set_x_orig)\n",
    "test_set_x_vectorized = image_preprocessing_simple(test_set_x_orig)\n",
    "\n",
    "print('Train set:')\n",
    "print(\"Размеры train_set_x_vectorized:  {}\".format(str(train_set_x_vectorized.shape)))\n",
    "print(\"Размеры train_set_y:             {}\".format(str(train_set_y.shape)))\n",
    "print(\"Размеры классов 'cat'/'non-cat': {} / {}\".format(sum(train_set_y==1), sum(train_set_y==0)))\n",
    "print('Test set:')\n",
    "print(\"Размеры test_set_x_vectorized:   {}\".format(str(test_set_x_vectorized.shape)))\n",
    "print(\"Размеры test_set_y:              {}\".format(str(test_set_y.shape)))\n",
    "print(\"Размеры классов 'cat'/'non-cat': {} / {}\".format(sum(test_set_y==1), sum(test_set_y==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос**: Какую метрику качества стоит использовать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Построение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим  модель с параметрами по умолчанию и посмотрим, как хорошо она справится с задачей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность для простой модели с параметрами по умолчанию: 1.0000\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(train_set_x_vectorized, train_set_y)\n",
    "score = clf.score(train_set_x_vectorized, train_set_y)\n",
    "print('Точность для простой модели с параметрами по умолчанию: {:.4f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc для простой модели: 0.7200\n",
      "f1_score для простой моделиЖ 0.7812\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_predicted = clf.predict(test_set_x_vectorized)\n",
    "correct_score = clf.score(test_set_x_vectorized, test_set_y)\n",
    "_f1_score = f1_score(test_set_y, y_predicted)\n",
    "print('acc для простой модели: {:.4f}'.format(correct_score))\n",
    "print('f1_score для простой моделиЖ {:.4f}'.format(_f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем подобрать параметры регуляризации в надежде, что это повысит точность предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.max_iter = 1000\n",
    "clf.solver = 'saga'\n",
    "clf.tol =0.0001\n",
    "clf.C = 2\n",
    "clf.penalty='elasticnet'\n",
    "clf.l1_ratio=0\n",
    "clf.fit(train_set_x_vectorized, train_set_y)\n",
    "score = clf.score(test_set_x_vectorized, test_set_y)\n",
    "y_pred = clf.predict(test_set_x_vectorized)\n",
    "_f1_score = f1_score(test_set_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальные параметры: 5000\n",
      "Наилучшее значение метрики качества f1: 0.7812499999999999\n",
      "Наилучшее значение метрики качества: 0.72\n"
     ]
    }
   ],
   "source": [
    "print('Оптимальные параметры: {}'.format(5000))\n",
    "print('Наилучшее значение метрики качества f1: {}'.format(_f1_score))\n",
    "print('Наилучшее значение метрики качества: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с оптимальными параметрами на всей обучающей выборке и посмотрим на метрики качества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal model hyperparameters accuracy score: 0.7812\n"
     ]
    }
   ],
   "source": [
    "best_clf = LogisticRegression()\n",
    "best_clf.fit(train_set_x_vectorized, train_set_y)\n",
    "\n",
    "y_predicted = best_clf.predict(test_set_x_vectorized)\n",
    "metric_score = f1_score(y_predicted, test_set_y)\n",
    "print('Optimal model hyperparameters accuracy score: {:.4f}'.format(metric_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Анализ ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_outlier = (y_predicted != test_set_y)\n",
    "test_outliers_x, test_outliers_y, predicted_y = test_set_x_orig[is_outlier], test_set_y[is_outlier], y_predicted[is_outlier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1337126b3ed8414ea071a694b4b67bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=13), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_image_outliers(i=0)>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_image_outliers(i=0):\n",
    "    f = plt.figure(figsize=(5,5))\n",
    "    plt.imshow(test_outliers_x[i])\n",
    "    plt.title('RGB image')\n",
    "    \n",
    "    fmt_string = \"Sample belongs to '{}' class, but '{}' is predicted'\"\n",
    "    print(fmt_string.format(classes[test_outliers_y[i]], classes[predicted_y[i]]))\n",
    "\n",
    "interact(show_image_outliers,\n",
    "         i=widgets.IntSlider(min=0, max=len(test_outliers_y)-1, step=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос**: Как по-вашему можно повысить точность? Каким недостатком обладает данный подход к классификации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Модель с аугментациями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно увеличить количество данных для обучения?\n",
    "\n",
    "Сформировать новые примеры из уже имеющихся!\n",
    "\n",
    "Например, можно пополнить class 'cat' обучающей выборки [зеркально отображёнными](https://docs.scipy.org/doc/numpy/reference/generated/numpy.fliplr.html) изображениями котов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_sample(src, label):\n",
    "    \n",
    "\n",
    "def image_preprocessing_augment(data, labels):\n",
    "    assert type(data) == np.ndarray\n",
    "    assert data.ndim == 4\n",
    "    \n",
    "    ## ВАШ КОД ##\n",
    "    \n",
    "    \n",
    "    data_augmented = \n",
    "    labels_augmented = \n",
    "    ## ВАШ КОД ЗАКАНЧИВАЕТСЯ ЗДЕСЬ ##\n",
    "    \n",
    "    n,h,w,c = data_augmented.shape\n",
    "    data_vectorized = data_augmented.reshape(n, -1) # <ваш код>\n",
    "    data_normalized = data_vectorized / 255\n",
    "    \n",
    "    return data_normalized, labels_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_augmented, train_set_y_augmented = image_preprocessing_augment(train_set_x_orig, train_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='liblinear')\n",
    "clf.fit(train_set_x_augmented, train_set_y_augmented)\n",
    "y_pred = clf.predict(test_set_x_vectorized)\n",
    "print('F-мера для модели с аугментациями: {:.4f}'.format(f1_score(y_pred, test_set_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Проверьте работу классификатора на своей картинке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека [OpenCV](https://opencv.org) для работы с изображениями для [python](https://pypi.org/project/opencv-python/):\n",
    "\n",
    "`pip install opencv-python`\n",
    "\n",
    "Вместе с contrib-модулями:\n",
    "\n",
    "`pip install opencv-contrib-python`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Путь к картинке на вашем ПК\n",
    "fname = \"cat-non-cat.jpg\"\n",
    "# Считываем картинку через scipy\n",
    "src = cv2.cvtColor(cv2.imread((fname)), cv2.COLOR_BGR2RGB)\n",
    "src_resized = cv2.resize(src, (src_size,src_size), interpolation=cv2.INTER_LINEAR).reshape(1, src_size*src_size*3)\n",
    "my_image_predict = clf.predict(src_resized)[0]\n",
    "\n",
    "plt.imshow(src)\n",
    "print(\"Алгоритм говорит, что это '{}': {}\".format(my_image_predict, classes[my_image_predict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
